# Intelligent-Systems-and-Technologies
Здесь вы можете найти проекты, выполненные в рамках курса ISnT.

## Lab 1 - Анализ и классификация ментальной работоспособности на основе RGB-сигналов.

### Описание
Проект направлен на анализ RGB-сигналов, полученных от 10 участников, с последующей классификацией уровней умственной работоспособности.

---

### Основные этапы

#### 1. Подготовка и анализ данных 
- Использованы файлы RGB-сигналов 10 участников. Данные включают временные ряды (колонки `t0–t59`), метку умственной работоспособности (`AU`) и дополнительную информацию в формате "22-12-28-rings-morning_min0" (`file`).
- Преобразована колонка `file` в отдельные столбцы: `date`, `time_of_day`, `minute`.
- Проведена аналитика RGB-сигналов для одного участника за 5 минут в разное время суток (утро, день, вечер).
- Создан единый файл `combined_data.csv`, объединяющий данные из всех каналов.
- Извлечены статистические, временные и частотные признаки и помещены в файл `features.csv`.
- Построены графики для анализа признаков по каналам, участникам и времени суток.

#### 2. Эксперименты с каналами
- Подготовка данных для классификации с использованием 1, 2 или всех 3 каналов (R, G, B) через метод `comb_channels`.
- Установлен порог классификации на основе 50-го перцентиля `AU`.

#### 3. Обучение и оценка моделей
- Протестированы модели: Random Forest, Logistic Regression, Support Vector Classifier (линейное и RBF ядра), MLP Classifier, Gaussian NB.
- Оценка производительности по Accuracy, Precision, Recall, F1-Score, Confusion Matrix.
- Анализ результатов: определена лучшая модель, произведено сравнение результатов по каналам и моделям.

#### 4. Визуализация результатов
- Построены столбчатые диаграммы и тепловая карта для анализа F1-Score по каналам и моделям.

---

### Используемые технологии
- **Python**
- Библиотеки:
  - `pandas`, `numpy`, `matplotlib`, `seaborn`
  - `scipy` 
  - `scikit-learn`

---

## Lab 2 - Разработка программного кода, который будет обрабатывать и раскрывать шифры.

### Описание
Предлагается набор текстов, которые являются научным комментарием к литературным произведениям. В данных текстах содержатся ссылки на архивные рукописи оформленные в виде шифров с указанием элементов рукописи.


Пример упоминания шифра рукописей в тексте:


**`в тетр. ПД 841, л. 20 об. — 23, 40 об. — 41 (черновой сцен «Светлица» и «Днепр. Ночь» (монолог Князя и песня русалок));`**
-  ПД 841 – архивное название документа;
-  л. 20 об. — 23, 40 об. — 41 – его составные элементы (листы), которые могут быть указаны в прямом и обратном порядке (у листа есть лицевая сторона и оборотная);
-  в скобках указан комментарий, в нём могут содержаться шифры, но не обязательно, если шифр указан в комментарии к найденному ранее шифру, то шифр в комментарии игнорируется;
-  комментарии могут разделять интервалы страниц, например ПД 52 л. 35 об. (черновой), 36 - 37 об. (беловой).


Пример приведённый выше, должен быть преобразован в следующую последовательность: 

**`ПД 841 л. 20 об.; ПД 841 л. 21; ПД 841 л. 21 об.; ПД 841 л. 22; ПД 841 л. 22 об.; ПД 841 л. 23; ПД 841 л. 40 об.; ПД 841 л. 41`**

---

### Основные этапы

#### 1. Подготовка и просмотр данных 
- Чтение исходного датасета: variant_3.csv. 
- Быстрый осмотр структуры: `df.head()`.

#### 2. Реализация методов
- `expand_doc_ranges_in_text()` - метод «разворачивает» диапазоны документов вида ПД A – ПД B или ПД A – B в явный перечень; сохраняет порядок появления в тексте; корректно обрабатывает как возрастающие, так и убывающие промежутки.
- `find_doc_chunks()` - метод ищет упоминания «ПД N» блоками и нормализует контекст.
- `expand_range()` - метод «разворачивает» диапазон листов л. A–B в последовательность конкретных сторон листов (лицевая и оборотная), учитывая, что у границ могут быть заданы стороны. Работает и для возрастающих, и для убывающих диапазонов, и для случая A==B.
- `process_leaf_group()` - метод принимает строку с перечислением листов и последовательно разворачивает её в список конкретных упоминаний листов.
- `extract_leaf_references()` - метод выдёргивает все ссылки на листы после л. из основного текста, игнорируя круглые скобки, и сразу нормализует их в список.
- `extract_from_chunk()` - метод берёт один «кусок» текста, где упоминаются ПД, и возвращает список кортежей (ПД N, [листы...]).

#### 3. Сборка результата и экспорт
- На каждой строке датасета берётся текст autographs, извлекаются все упоминания «ПД … л. …», разворачивает диапазоны/«об.», игнорирует нерелевантные скобки, формирует упорядоченный список ссылок и сохраняет в `output.csv`.

---

### Используемые технологии
- **Python**
- Библиотеки:
  - `pandas`, `re`